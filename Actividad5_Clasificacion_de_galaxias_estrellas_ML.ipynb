{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Actividad5-Clasificacion-de-galaxias-estrellas-ML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astrodatos/Clase5/blob/master/Actividad5_Clasificacion_de_galaxias_estrellas_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9sflCJ9zlA-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# EI2001: Ciencia de Datos en Astronomía\n",
        "**Profesores:** Pía Cortés, Daniela Barrientos, Matías Suazo, Matías Mattamala\n",
        "\n",
        "# Actividad Clase 5 - Clasificación con Machine Learning\n",
        "## Separando estrellas de galaxias con los datos de SDSS\n",
        "\n",
        "**Objetivos:** \n",
        "1. Introducción al Machine Learning en Python\n",
        "2. Librería Scikit Learn\n",
        "3. Uso de Métodos de clasificacion\n",
        "4. Preaparacion de datos\n",
        "5. Creacion de Modelo\n",
        "6. Clasificación\n",
        " \n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "AgwJeI8YaDuD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Antes de comenzar la actividad, instalaremos el paquete de descarga de bases de datos astronómicas  [`astroquery`](https://astroquery.readthedocs.io/en/latest/). \n",
        "\n",
        "Ejecuta la siguiente celda, que realizará la instalación del paquete en tu entorno de ejecución temporal. "
      ]
    },
    {
      "metadata": {
        "id": "Gw23RcpJlPbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Al agregar ! convertimos nuestro codigo de python a bash (lenguaje usado en la terminal)\n",
        "!pip install --pre  --quiet astroquery"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztOQu7kaFdHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Motivación \n",
        "## ¿Por qué usar algoritmos de Aprendizaje de Máquinas?\n",
        "\n",
        "\n",
        "Muchas de las aplicaciones de la ciencia hecha a partir de surveys astronómicos, dependen de la clasificación inicial de los objetos observados. Por ejemplo, pongámonos en el caso de querer estudiar la estructura de la Vía Láctea a partir de observaciones como las de SDSS o futuramente LSST. Estas imágenes contienen tanto estrellas locales como galaxias en sus imágenes, por lo que el paso cero de nuestra investigación sería separar las estrellas de las galaxias en nuestros catálogos. \n",
        "\n",
        "Ahora, ¿por qué es necesario usar Machine Learning para esto? \n",
        "\n",
        "Generalmente obtener una clasificación es caro. En el contexto de nuestro problema de estrellas versus galaxias, la clasificación real es confirmada mediante espectroscopía. Pero, obtener espectros requiere de tiempos de exposición mayores y no se realiza para todas las fuentes. En SDSS existen $\\gt 10^{8}$ fuentes, de las cuales solo $\\sim 10^{6}$ tienen espectros.\n",
        "\n",
        "![Espectros](https://raw.githubusercontent.com/astrodatos/Clase5/master/imagenes/espectros.png)\n",
        "\n",
        "Por otro lado, podemos hacernos una idea de la clasificación entre estrella y galaxia mirando las imágenes, las estrellas son objetos puntuales, mientras que las galaxias son extendidas. Pero esto necesitaría de una inspección visual para cada fuente en el catálogo, lo que nuevamente, es muy caro.\n",
        "\n",
        "![Imágen Estrella](https://raw.githubusercontent.com/astrodatos/Clase5/master/imagenes/estrella.png =300x300)      ![Imágen Galaxia](https://github.com/astrodatos/Clase5/raw/master/imagenes/gal.png =300x300)\n",
        "\n",
        "Aquí es donde el Machine Learning puede ayudarnos. A través del uso de algoritmos de ML podemos encontrar una separación de los objetos en nuestros catálogos en el espacio de múltiples de sus atributos. Muchas veces esta separación sucede en un espacio de varias dimensiones, que seríamos incapaces de detectar de otro modo."
      ]
    },
    {
      "metadata": {
        "id": "y5KMFHBUlA-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "%matplotlib inline\n",
        "#%matplotlib notebook\n",
        "\n",
        "\n",
        "#Cambiar formato de graficos\n",
        "\n",
        "plt.rcParams.update({'axes.labelsize' : 18})\n",
        "plt.rcParams.update({'axes.titlesize' : 20})\n",
        "plt.rcParams.update({'legend.fontsize' : 15})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OvLWXFbH85RM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El siguiente es un ejemplo de cómo aumentar las dimensiones a veces revela separaciones en nuestros datos. "
      ]
    },
    {
      "metadata": {
        "id": "CN8EZ814dcHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definimos las posiciones para 3 nubes de puntos\n",
        "\n",
        "b1_x = np.random.normal(2, 0.5, 100) \n",
        "b2_x = np.random.normal(1, 0.5, 100)\n",
        "b3_x = np.random.normal(5, 0.5, 100)\n",
        "\n",
        "b1_y = np.random.normal(1, 0.5, 100) \n",
        "b2_y = np.random.normal(1, 0.5, 100)\n",
        "b3_y = np.random.normal(5, 0.5, 100)\n",
        "\n",
        "b1_z = np.random.normal(1, 0.5, 100) \n",
        "b2_z = np.random.normal(5, 0.5, 100)\n",
        "b3_z = np.random.normal(5, 0.5, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NWWbTem6c4bZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (10,6))\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.scatter3D(b1_x,b1_y,b1_z, color = 'r', label = 'c1')\n",
        "ax.scatter3D(b2_x,b2_y,b2_z, color = 'b', label = 'c2')\n",
        "ax.scatter3D(b3_x,b3_y,b3_z, color = 'g', label = 'c3')\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "ax.view_init(90, 90)\n",
        "ax.legend()\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kTH6sxgwlA-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preparación de Datos\n",
        "\n",
        "## Sloan Digital Sky Survey ([SDSS](https://www.sdss.org/))\n",
        "\n",
        "\n",
        "Los datos que utilizaremos para crear nuestro modelo de clasificación provendran del Sloan Digital Sky Survey, un proyecto astronómico que mapeó distintas zonas del cielo realizando tanto imágenes como espectros para una cantidad enorme de fuentes. \n",
        "\n",
        "Esto nos da la ventaja de obtener tanto los atributos, en este caso la fotometría, como las clases, que fueron obtenidas mediante espectros, a partir del mismo set de datos.\n",
        "\n",
        "La gente de SDSS además de obtener los espectros e imágenes 'crudas' en multiples bandas, procesó estos datos para obtener la fotometría y una serie de parámetros por fuente. (Puedes mirar la lista de parámetros y sus definiciones [aqui](http://skyserver.sdss.org/dr15/en/help/browser/browser.aspx#&&history=description+PhotoObjAll+U)).\n",
        "\n",
        "No podemos usar las 454  propiedades calculadas por objeto, es por esto que el primer paso en la construcción de nuestro clasificador será elegir los atributos a utilizar en esta clasificación.  \n",
        "\n",
        "Para este ejemplo básico nos limitaremos a utilizar solo la fotometría en la banda r, obtenida mediante diferentes modelamientos.\n",
        " \n",
        " \n"
      ]
    },
    {
      "metadata": {
        "id": "GHjTiOF5lA-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cargar Datos desde SDSS\n",
        "\n",
        "El paquete de python `astroquery` nos provee de una herramienta para acceder a las bases de datos de múltiples surveys astronómicos. En este caso utilizaremos sus módulos para extraer datos de SDSS. \n",
        "\n",
        "El formato para realizar la petición es la siguiente:\n",
        "\n",
        "* __SELECT__: columnas que se quiere obtener.\n",
        "  * Fotometría en la banda r, para distintos modelos fotométricos.\n",
        "    * Atributos: `psfMag_r`, `fiberMag_r`, `fiber2Mag_r`, `petroMag_r`, `devMag_r`, `expMag_r`,\n",
        "  `modelMag_r`, `cModelMag_r`\n",
        "    * Clases: `class`  \n",
        "  \n",
        "\n",
        "* __FROM__: tabla desde donde obtener datos.\n",
        "  * Fotometría desde `PhotoObjAll` y clases de `specObjAll`.\n",
        "\n",
        "* __WHERE__: condiciones para elegir las fuentes.\n",
        "  * Se eligen objetos con buena fotometría y que solo sean de las clases Star y Galaxy.\n"
      ]
    },
    {
      "metadata": {
        "id": "ijg_JSXklA-d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from astroquery.sdss import SDSS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CIljmyJulA-r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Vamos a seleccionar 20000 objetos de los catálogos de SDSS\n",
        "\n",
        "data = SDSS.query_sql(\"\"\"SELECT TOP 20000\n",
        "                      p.psfMag_r, p.fiberMag_r, p.fiber2Mag_r, p.petroMag_r, \n",
        "                      p.deVMag_r, p.expMag_r, p.modelMag_r, p.cModelMag_r, \n",
        "                      s.class\n",
        "                      \n",
        "                      FROM PhotoObjAll AS p JOIN specObjAll s ON s.bestobjid = p.objid\n",
        "                      \n",
        "                      WHERE p.mode = 1 AND s.sciencePrimary = 1 AND p.clean = 1 AND s.class != 'QSO'\n",
        "                      \n",
        "                      \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUCkIRO4lA-2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cambiamos el formato de la tabla obtenida con astroquery a pandas.\n",
        "\n",
        "data_df = data.to_pandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8DgTojnmf9mS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Miremos los primeros 10 objetos\n",
        "\n",
        "data_df[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGpc6iNL_XKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como podemos ver, nuestra tabla contiene 8 columnas de atributos y una columna con las clases: 'STAR' y 'GALAXY'."
      ]
    },
    {
      "metadata": {
        "id": "tGsLGf2TlA-8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizacion de los datos\n",
        "\n",
        "Siempre es bueno, antes de comenzar cualquier proyecto científico, hacer una exploración visual de nuestros datos. \n",
        "\n",
        "Queremos hacernos una idea general del comportamiento de nuestros datos. Como, qué atributos parecen más importantes, si existen separaciones marcadas en algunas de las características, etc. \n",
        "\n",
        "Vamos a utilizar el método  [`pairplot`](https://seaborn.pydata.org/generated/seaborn.pairplot.html) del paquete `Seaborn`, para graficar tanto las distribuciones de nuestros parámetros como las relaciones entre ellos. \n"
      ]
    },
    {
      "metadata": {
        "id": "dSovcR-NlA--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.pairplot(data_df, hue = 'class', diag_kind = 'hist')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fZX7fmtNlA_L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hay alguna separacion obvia? Miremos más de cerca algunos de los atributos."
      ]
    },
    {
      "metadata": {
        "id": "c_zQM8W8lA_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.pairplot(data_df[['psfMag_r', 'modelMag_r', 'fiber2Mag_r', 'class']], hue = 'class')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUOZCtiNlA_h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Separacion de Datos\n",
        "\n",
        "Como vimos en la Clase 5, el procedimiento estándar al realizar Aprendizaje Supervisado (cuando tenemos clases para nuestros objetos) es entrenar nuestro modelo en una porción de nuestros datos, para luego probar su precisión en lo que resta de ellos. \n",
        "\n",
        "Además debemos separar nuestra tabla en dos, una que contenga los atributos y otra que contenga las clases. \n"
      ]
    },
    {
      "metadata": {
        "id": "HDV2GzFElA_m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Miremos primero la lista con los nombres de las columnas\n",
        "list(data_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aeGmN3K0Ab60",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para realizar la construcción de nuestros modelos utilizaremos el paquete de Python [`Scikit Learn`](https://scikit-learn.org/stable/). Scikit learn requiere que nuestros datos esten en alguna estructura de datos donde las columnas sean los atributos y las filas los objetos. \n",
        "\n",
        "Pero es necesario que nuestros atributos y clases tengan un formato numérico. Afortunadamente, en Astronomía la mayoría de las veces vamos a tratar con atributos numéricos y no es necesario tanto procesamiento. \n",
        "\n",
        "En este caso solo debemos preocuparnos de transformar las clases, ya que de momento son _strings_. "
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "DtoyhiMdlA_v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Primero identificamos las clases existentes \n",
        "\n",
        "clases = data_df['class'].unique()\n",
        "\n",
        "mapa = {}\n",
        "\n",
        "for clase, i in enumerate(clases):\n",
        "    mapa[i] = clase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "afzEd2BklA_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creamos un mapeo entre las clases originales (strings) y las nuevas (enteros)\n",
        "mapa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S2-rb_mXlBAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Separamos entre atributos y clases (cambiando el formato de las clases)\n",
        "\n",
        "X = np.array(data_df.iloc[:,:-1])          # Arreglo con atributos\n",
        "\n",
        "\n",
        "y = np.array(data_df['class'].map(mapa))   # Arreglo con clases 0 y 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PMa2St9TCT5C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Una cosa importante de considerar al hacer la separación de nuestros datos en sets de entrenamiento y prueba, es la distribución de las clases en ellos. La separación debe ser realizada de tal forma que todas las clases esten representadas en ambos conjuntos. "
      ]
    },
    {
      "metadata": {
        "id": "lbte04udlBAL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Usamos una funcion de scikit learn para dividir nuestro conjunto al azar\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "rs = 1851   #Guardamos la semilla \n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = rs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FlxmO33K4euE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Veamos las distribuciones de clases para cada set\n",
        "\n",
        "plt.figure(figsize = (10,5))\n",
        "\n",
        "plt.hist(train_y, label = 'Entrenamiento')\n",
        "plt.hist(test_y, label = 'Prueba')\n",
        "plt.xlabel('Clases')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nvXsj-3QlBAT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creación del Modelo de Clasificación.\n",
        "\n",
        "Ahora que separamos nuestro conjunto de datos estamos listos para crear nuestro modelo de clasificación. Existen varios modelos que podemos usar para realizar Aprendizaje Supervisado [implementados en scikit-learn](https://scikit-learn.org/stable/supervised_learning.html). Para este caso de ejemplo, utilizaremos un clasificador llamado _k Nearest Neighbors_.\n",
        "\n",
        "\n",
        "### K Nearest Neighbors (kNN) - k Vecinos mas próximos.\n",
        "\n",
        "La clasificación se realiza en base a las clases de los vecinos más proximos, para un cierto $k$ se realiza un conteo de las clases correspondientes a los $k$ vecinos más próximos y se asigna al nuevo objeto la clase más popular. \n",
        "\n",
        "![texto alternativo](https://thumbs.gfycat.com/WildSorrowfulChevrotain-size_restricted.gif)\n",
        "\n",
        "\n",
        "La clasificación, luego, va a depender de la __cantidad de vecinos a considerar__. \n",
        "\n",
        "(Nota que para poder utilizar este algoritmo debemos evaluar la distancia entre nuestros objetos, lo que podría ser problemático dependiendo del tipo de datos que tengamos).\n",
        "\n",
        "![texto alternativo](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/279px-KnnClassification.svg.png =400x350)\n",
        "\n",
        "([scikit learn kNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html))\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iGsuENRqlBAX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Inincializar un modelo"
      ]
    },
    {
      "metadata": {
        "id": "7Vve9pcAlBAZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Vamos a utilizar la implementacion del algoritmo knn de scikitlearn\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=25)   # Debemos especificar el numero\n",
        "                                                 #de vecinos, en este caso escogemos 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OGCee92MKivi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn_clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7iO59l7lBAh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Ajustar a los datos\n",
        "\n",
        "Esta es la fase de _entrenamiento_ de nuestro modelo. Aqui es cuando nuestro modelo aprenderá la clasificación a partir de los datos en el conjunto de entrenamiento.\n",
        "\n",
        "En `scikit-learn`, esto es tan fácil como utilizar el método:\n",
        "\n",
        "__`modelo.fit(atributos, clases)`__"
      ]
    },
    {
      "metadata": {
        "id": "egnByiRblBAi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utilizamos el metodo .fit para entrenar nuestro clasificador\n",
        "\n",
        "knn_clf.fit(train_X, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Hi3aHbIlBA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Testear modelo haciendo predicciones\n",
        "\n",
        "Una vez entrenado nuestro modelo, podemos hacer clasificaciones para datos independientes. En esta fase vamos a validar la precisión de nuestro clasificador. \n",
        "\n",
        "Para esto haremos uso del conjunto de datos de prueba. Nuestra estrategia será predecir clases para cada objeto en nuestro conjunto a partir de sus atributos y luego comparar estas con la clases reales.\n",
        "\n",
        "En scikit-learn las predicciones se hacen mediante el método:\n",
        "\n",
        "__`modelo.predict(atributos)`__"
      ]
    },
    {
      "metadata": {
        "id": "mIc_vMVSlBA4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hacemos la clasificacion del set de prueba\n",
        "\n",
        "pred_test = knn_clf.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oRDs-Z0QlBBC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dkS9jNddlBBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w0vnGVfLMLgt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Al igual que nuestras clases, el resultado de las predicciones es un arreglo de 0s y 1s, representando la clasificación entre galaxias y estrellas. Podemos ver que tan precisa es esta clasificación comparando estas etiquetas."
      ]
    },
    {
      "metadata": {
        "id": "moW1LmPjlBBZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(pred_test - test_y)\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Clase Predicha - Clase Real')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YL1RqhZAM3SZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Matriz de Confusión\n",
        "\n",
        "Una forma estándar y sencilla de evaluar la precisión de un modelo de aprendizaje supervisado es a través de la Matriz de Confusión. \n",
        "\n",
        "En esta matriz las __columnas__ representan las __predicciones__ hechas para cada clase, mientras que las __filas__ representan las instancias de la clase real. \n",
        "\n",
        "Las matrices de confusión son muy buenas para identificar cuando el algoritmo esta confundiendo dos clases específicamente. \n",
        "\n",
        "![texto alternativo](https://sandipanweb.files.wordpress.com/2017/07/confusion.png?w=676)"
      ]
    },
    {
      "metadata": {
        "id": "CWzYLoCqlBBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utilizaremos la implementación de scikit-learn de esta matriz\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vnQEo7qMlBBo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Obtengamos nuestra matriz de confusion\n",
        "\n",
        "confusion_matrix(test_y, pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YQFv-oVflBBz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Scikit-learn nos ofrece una implementación gráfica de la Matriz de Confusión, que nos permite ver sencillamente (con colores) el rendimiento de nuestro algoritmo.\n",
        "\n",
        "[Fuente del código para la matriz de confusión implementada](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)"
      ]
    },
    {
      "metadata": {
        "id": "GKR71I7plBB2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Matriz de confusion normalizada'\n",
        "        else:\n",
        "            title = 'Matriz de confusion, sin normalizacion'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Matriz de confusion normalizada\")\n",
        "    else:\n",
        "        print('Matriz de confusion, sin normalizacion')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize = (8,8))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='Etiqueta Real',\n",
        "           xlabel='Etiqueta Predicha')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\", fontsize=15)\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt), fontsize=25,\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "            \n",
        "    ax.grid(False)\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BstGhe9ilBCA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(test_y, pred_test, classes=clases,\n",
        "                      title='Matriz de confusion, sin normalizacion')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7hJohEyw1S1t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(test_y, pred_test, classes=clases, normalize = True,\n",
        "                      title='Matriz de confusion, con normalizacion')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}